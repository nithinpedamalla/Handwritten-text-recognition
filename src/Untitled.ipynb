{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b156ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import html\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, Dict, Sequence, Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import albumentations as A\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from util import read_xml, find_child_by_tag, set_seed, LabelEncoder\n",
    "from transforms import IAMImageTransforms\n",
    "\n",
    "\n",
    "class IAMDataset(Dataset):\n",
    "    MEAN = 0.8275\n",
    "    STD = 0.2314\n",
    "    MAX_FORM_HEIGHT = 3542\n",
    "    MAX_FORM_WIDTH = 2479\n",
    "\n",
    "    MAX_SEQ_LENS = {\n",
    "        \"word\": 55,\n",
    "        \"line\": 90,\n",
    "        \"form\": 700,\n",
    "    }  # based on the maximum seq lengths found in the dataset\n",
    "\n",
    "    _pad_token = \"<PAD>\"\n",
    "    _sos_token = \"<SOS>\"\n",
    "    _eos_token = \"<EOS>\"\n",
    "\n",
    "    root: Path\n",
    "    data: pd.DataFrame\n",
    "    label_enc: LabelEncoder\n",
    "    parse_method: str\n",
    "    only_lowercase: bool\n",
    "    transforms: Optional[A.Compose]\n",
    "    id_to_idx: Dict[str, int]\n",
    "    _split: str\n",
    "    _return_writer_id: Optional[bool]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Union[Path, str],\n",
    "        parse_method: str,\n",
    "        split: str,\n",
    "        return_writer_id: bool = False,\n",
    "        only_lowercase: bool = False,\n",
    "        label_enc: Optional[LabelEncoder] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        _parse_methods = [\"form\", \"line\", \"word\"]\n",
    "        err_message = (\n",
    "            f\"{parse_method} is not a possible parsing method: {_parse_methods}\"\n",
    "        )\n",
    "        assert parse_method in _parse_methods, err_message\n",
    "\n",
    "        _splits = [\"train\", \"test\"]\n",
    "        err_message = f\"{split} is not a possible split: {_splits}\"\n",
    "        assert split in _splits, err_message\n",
    "\n",
    "        self._split = split\n",
    "        self._return_writer_id = return_writer_id\n",
    "        self.only_lowercase = only_lowercase\n",
    "        self.root = Path(root)\n",
    "        self.label_enc = label_enc\n",
    "        self.parse_method = parse_method\n",
    "\n",
    "        # Process the data.\n",
    "        if not hasattr(self, \"data\"):\n",
    "            if self.parse_method == \"form\":\n",
    "                self.data = self._get_forms()\n",
    "            elif self.parse_method == \"word\":\n",
    "                self.data = self._get_words(skip_bad_segmentation=True)\n",
    "            elif self.parse_method == \"line\":\n",
    "                self.data = self._get_lines()\n",
    "\n",
    "        # Create the label encoder.\n",
    "        if self.label_enc is None:\n",
    "            vocab = [self._pad_token, self._sos_token, self._eos_token]\n",
    "            s = \"\".join(self.data[\"target\"].tolist())\n",
    "            if self.only_lowercase:\n",
    "                s = s.lower()\n",
    "            vocab += sorted(list(set(s)))\n",
    "            self.label_enc = LabelEncoder().fit(vocab)\n",
    "        if not \"target_enc\" in self.data.columns:\n",
    "            self.data.insert(\n",
    "                2,\n",
    "                \"target_enc\",\n",
    "                self.data[\"target\"].apply(\n",
    "                    lambda s: np.array(\n",
    "                        self.label_enc.transform(\n",
    "                            [c for c in (s.lower() if self.only_lowercase else s)]\n",
    "                        )\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.transforms = self._get_transforms(split)\n",
    "        self.id_to_idx = {\n",
    "            Path(self.data.iloc[i][\"img_path\"]).stem: i for i in range(len(self))\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data.iloc[idx]\n",
    "        img = cv.imread(data[\"img_path\"], cv.IMREAD_GRAYSCALE)\n",
    "        if all(col in data.keys() for col in [\"bb_y_start\", \"bb_y_end\"]):\n",
    "            # Crop the image vertically.\n",
    "            img = img[data[\"bb_y_start\"] : data[\"bb_y_end\"], :]\n",
    "        assert isinstance(img, np.ndarray), (\n",
    "            f\"Error: image at path {data['img_path']} is not properly loaded. \"\n",
    "            f\"Is there something wrong with this image?\"\n",
    "        )\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        if self._return_writer_id:\n",
    "            return img, data[\"writer_id\"], data[\"target_enc\"]\n",
    "        return img, data[\"target_enc\"]\n",
    "\n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self.label_enc.classes\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(\n",
    "        batch: Sequence[Tuple[np.ndarray, np.ndarray]],\n",
    "        pad_val: int,\n",
    "        eos_tkn_idx: int,\n",
    "        dataset_returns_writer_id: bool = False,\n",
    "    ) -> Union[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor, Tensor]]:\n",
    "        if dataset_returns_writer_id:\n",
    "            imgs, writer_ids, targets = zip(*batch)\n",
    "        else:\n",
    "            imgs, targets = zip(*batch)\n",
    "\n",
    "        img_sizes = [im.shape for im in imgs]\n",
    "        if (\n",
    "            not len(set(img_sizes)) == 1\n",
    "        ):  # images are of varying sizes, so pad them to the maximum size in the batch\n",
    "            hs, ws = zip(*img_sizes)\n",
    "            pad_fn = A.PadIfNeeded(\n",
    "                max(hs), max(ws), border_mode=cv.BORDER_CONSTANT, value=0\n",
    "            )\n",
    "            imgs = [pad_fn(image=im)[\"image\"] for im in imgs]\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "\n",
    "        seq_lengths = [t.shape[0] for t in targets]\n",
    "        targets_padded = np.full((len(targets), max(seq_lengths) + 1), pad_val)\n",
    "        for i, t in enumerate(targets):\n",
    "            targets_padded[i, : seq_lengths[i]] = t\n",
    "            targets_padded[i, seq_lengths[i]] = eos_tkn_idx\n",
    "\n",
    "        imgs, targets_padded = torch.tensor(imgs), torch.tensor(targets_padded)\n",
    "        if dataset_returns_writer_id:\n",
    "            return imgs, targets_padded, torch.tensor(writer_ids)\n",
    "        return imgs, targets_padded\n",
    "\n",
    "    def set_transforms_for_split(self, split: str):\n",
    "        _splits = [\"train\", \"val\", \"test\"]\n",
    "        err_message = f\"{split} is not a possible split: {_splits}\"\n",
    "        assert split in _splits, err_message\n",
    "        self.transforms = self._get_transforms(split)\n",
    "\n",
    "    def _get_transforms(self, split: str) -> A.Compose:\n",
    "        max_img_w = self.MAX_FORM_WIDTH\n",
    "\n",
    "        if self.parse_method == \"form\":\n",
    "            max_img_h = (self.data[\"bb_y_end\"] - self.data[\"bb_y_start\"]).max()\n",
    "        else:  # word or line\n",
    "            max_img_h = self.MAX_FORM_HEIGHT\n",
    "        transforms = IAMImageTransforms(\n",
    "            (max_img_h, max_img_w), self.parse_method, (IAMDataset.MEAN, IAMDataset.STD)\n",
    "        )\n",
    "\n",
    "        if split == \"train\":\n",
    "            return transforms.train_trnsf\n",
    "        elif split == \"test\" or split == \"val\":\n",
    "            return transforms.test_trnsf\n",
    "\n",
    "    def statistics(self) -> Dict[str, float]:\n",
    "        assert len(self) > 0\n",
    "        tmp = self.transforms\n",
    "        self.transforms = None\n",
    "        mean, std, cnt = 0, 0, 0\n",
    "        for img, _ in self:\n",
    "            mean += np.mean(img)\n",
    "            std += np.var(img)\n",
    "            cnt += 1\n",
    "        mean /= cnt\n",
    "        std = np.sqrt(std / cnt)\n",
    "        self.transforms = tmp\n",
    "        return {\"mean\": mean, \"std\": std}\n",
    "\n",
    "    def _get_forms(self) -> pd.DataFrame:\n",
    "        \"\"\"Read all form images from the IAM dataset.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame\n",
    "                A pandas dataframe containing the image path, image id, target, vertical\n",
    "                upper bound, vertical lower bound, and target length.\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            \"img_path\": [],\n",
    "            \"img_id\": [],\n",
    "            \"target\": [],\n",
    "            \"bb_y_start\": [],\n",
    "            \"bb_y_end\": [],\n",
    "            \"target_len\": [],\n",
    "        }\n",
    "        for form_dir in [\"formsA-D\", \"formsE-H\", \"formsI-Z\"]:\n",
    "            dr = self.root / form_dir\n",
    "            for img_path in dr.iterdir():\n",
    "                doc_id = img_path.stem\n",
    "                xml_root = read_xml(self.root / \"xml\" / (doc_id + \".xml\"))\n",
    "\n",
    "                # Based on some empiricial evaluation, the 'asy' and 'dsy'\n",
    "                # attributes of a line xml tag seem to correspond to its upper and\n",
    "                # lower bound, respectively. We add padding of 150 pixels.\n",
    "                bb_y_start = int(xml_root[1][0].get(\"asy\")) - 150\n",
    "                bb_y_end = int(xml_root[1][-1].get(\"dsy\")) + 150\n",
    "\n",
    "                form_text = []\n",
    "                for line in xml_root.iter(\"line\"):\n",
    "                    form_text.append(html.unescape(line.get(\"text\", \"\")))\n",
    "\n",
    "                img_w, img_h = Image.open(str(img_path)).size\n",
    "                data[\"img_path\"].append(str(img_path))\n",
    "                data[\"img_id\"].append(doc_id)\n",
    "                data[\"target\"].append(\"\\n\".join(form_text))\n",
    "                data[\"bb_y_start\"].append(bb_y_start)\n",
    "                data[\"bb_y_end\"].append(bb_y_end)\n",
    "                data[\"target_len\"].append(len(\"\\n\".join(form_text)))\n",
    "        return pd.DataFrame(data).sort_values(\n",
    "            \"target_len\"\n",
    "        )  # by default, sort by target length\n",
    "\n",
    "    def _get_lines(self, skip_bad_segmentation: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Read all line images from the IAM dataset.\n",
    "\n",
    "        Args:\n",
    "            skip_bad_segmentation (bool): skip lines that have the\n",
    "                segmentation='err' xml attribute\n",
    "        Returns:\n",
    "            List of 2-tuples, where each tuple contains the path to a line image\n",
    "            along with its ground truth text.\n",
    "        \"\"\"\n",
    "        data = {\"img_path\": [], \"img_id\": [], \"target\": []}\n",
    "        root = self.root / \"lines\"\n",
    "        for d1 in root.iterdir():\n",
    "            for d2 in d1.iterdir():\n",
    "                doc_id = d2.name\n",
    "                xml_root = read_xml(self.root / \"xml\" / (doc_id + \".xml\"))\n",
    "                for img_path in d2.iterdir():\n",
    "                    target = self._find_line(\n",
    "                        xml_root, img_path.stem, skip_bad_segmentation\n",
    "                    )\n",
    "                    if target is not None:\n",
    "                        data[\"img_path\"].append(str(img_path.resolve()))\n",
    "                        data[\"img_id\"].append(doc_id)\n",
    "                        data[\"target\"].append(target)\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def _get_words(self, skip_bad_segmentation: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Read all word images from the IAM dataset.\n",
    "\n",
    "        Args:\n",
    "            skip_bad_segmentation (bool): skip lines that have the\n",
    "                segmentation='err' xml attribute\n",
    "        Returns:\n",
    "            List of 2-tuples, where each tuple contains the path to a word image\n",
    "            along with its ground truth text.\n",
    "        \"\"\"\n",
    "        data = {\"img_path\": [], \"img_id\": [], \"writer_id\": [], \"target\": []}\n",
    "        root = self.root / \"words\"\n",
    "        for d1 in root.iterdir():\n",
    "            for d2 in d1.iterdir():\n",
    "                doc_id = d2.name\n",
    "                xml_root = read_xml(self.root / \"xml\" / (doc_id + \".xml\"))\n",
    "                writer_id = int(xml_root.get(\"writer-id\"))\n",
    "                for img_path in d2.iterdir():\n",
    "                    target = self._find_word(\n",
    "                        xml_root, img_path.stem, skip_bad_segmentation\n",
    "                    )\n",
    "                    if target is not None:\n",
    "                        data[\"img_path\"].append(str(img_path.resolve()))\n",
    "                        data[\"img_id\"].append(doc_id)\n",
    "                        data[\"writer_id\"].append(writer_id)\n",
    "                        data[\"target\"].append(target)\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def _find_line(\n",
    "        self,\n",
    "        xml_root: ET.Element,\n",
    "        line_id: str,\n",
    "        skip_bad_segmentation: bool = False,\n",
    "    ) -> Union[str, None]:\n",
    "        line = find_child_by_tag(xml_root[1].findall(\"line\"), \"id\", line_id)\n",
    "        if line is not None and not (\n",
    "            skip_bad_segmentation and line.get(\"segmentation\") == \"err\"\n",
    "        ):\n",
    "            return html.unescape(line.get(\"text\"))\n",
    "        return None\n",
    "\n",
    "    def _find_word(\n",
    "        self,\n",
    "        xml_root: ET.Element,\n",
    "        word_id: str,\n",
    "        skip_bad_segmentation: bool = False,\n",
    "    ) -> Union[str, None]:\n",
    "        line_id = \"-\".join(word_id.split(\"-\")[:-1])\n",
    "        line = find_child_by_tag(xml_root[1].findall(\"line\"), \"id\", line_id)\n",
    "        if line is not None and not (\n",
    "            skip_bad_segmentation and line.get(\"segmentation\") == \"err\"\n",
    "        ):\n",
    "            word = find_child_by_tag(line.findall(\"word\"), \"id\", word_id)\n",
    "            if word is not None:\n",
    "                return html.unescape(word.get(\"text\"))\n",
    "        return None\n",
    "\n",
    "\n",
    "class IAMSyntheticDataGenerator(Dataset):\n",
    "    \"\"\"\n",
    "    Data generator that creates synthetic line/form images by stitching together word\n",
    "    images from the IAM dataset.\n",
    "    Calling `__getitem__()` samples a newly generated synthetic image every time\n",
    "    it is called.\n",
    "    \"\"\"\n",
    "\n",
    "    PUNCTUATION = [\",\", \".\", \";\", \":\", \"'\", '\"', \"!\", \"?\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        iam_root: Union[str, Path],\n",
    "        label_encoder: Optional[LabelEncoder] = None,\n",
    "        transforms: Optional[A.Compose] = None,\n",
    "        line_width: Tuple[int, int] = (1500, 2000),\n",
    "        lines_per_form: Tuple[int, int] = (1, 11),\n",
    "        words_per_line: Tuple[int, int] = (4, 10),\n",
    "        words_per_sequence: Tuple[int, int] = (7, 13),\n",
    "        px_between_lines: Tuple[int, int] = (25, 100),\n",
    "        px_between_words: int = 50,\n",
    "        px_around_image: Tuple[int, int] = (100, 200),\n",
    "        sample_form: bool = False,\n",
    "        only_lowercase: bool = False,\n",
    "        rng_seed: int = 0,\n",
    "        max_height: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.iam_root = iam_root\n",
    "        self.label_enc = label_encoder\n",
    "        self.transforms = transforms\n",
    "        self.line_width = line_width\n",
    "        self.lines_per_form = lines_per_form\n",
    "        self.words_per_line = words_per_line\n",
    "        self.words_per_sequence = words_per_sequence\n",
    "        self.px_between_lines = px_between_lines\n",
    "        self.px_between_words = px_between_words\n",
    "        self.px_around_image = px_around_image\n",
    "        self.sample_form = sample_form\n",
    "        self.only_lowercase = only_lowercase\n",
    "        self.rng_seed = rng_seed\n",
    "        self.max_height = max_height\n",
    "\n",
    "        self.iam_words = IAMDataset(\n",
    "            iam_root,\n",
    "            \"word\",\n",
    "            \"test\",\n",
    "            only_lowercase=only_lowercase,\n",
    "        )\n",
    "        if self.max_height is None:\n",
    "            self.max_height = IAMDataset.MAX_FORM_HEIGHT\n",
    "        if sample_form and \"\\n\" not in self.label_encoder.classes:\n",
    "            # Add the `\\n` token to the label encoder (since forms can contain newlines)\n",
    "            self.label_encoder.add_classes([\"\\n\"])\n",
    "        self.iam_words.transforms = None\n",
    "        self.rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        # This dataset does not have a finite length since it can generate random\n",
    "        # images at will, so return 1.\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def label_encoder(self):\n",
    "        if self.label_enc is not None:\n",
    "            return self.label_enc\n",
    "        return self.iam_words.label_enc\n",
    "\n",
    "    def __getitem__(self, *args, **kwargs):\n",
    "        \"\"\"By calling this method, a newly generated synthetic image is sampled.\"\"\"\n",
    "        if self.sample_form:\n",
    "            img, target = self.generate_form()\n",
    "        else:\n",
    "            img, target = self.generate_line()\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        # Encode the target sequence using the label encoder.\n",
    "        target_enc = np.array(self.label_encoder.transform([c for c in target]))\n",
    "        return img, target_enc\n",
    "\n",
    "    def generate_line(self) -> Tuple[np.ndarray, str]:\n",
    "        words_to_sample = self.rng.integers(*self.words_per_line)\n",
    "        line_width = self.rng.integers(*self.line_width)\n",
    "        return self.sample_lines(words_to_sample, line_width, sample_one_line=True)\n",
    "\n",
    "    def generate_form(self) -> Tuple[np.ndarray, str]:\n",
    "        # Randomly pick the number of words and inter-line distance in the form.\n",
    "        words_to_sample = self.rng.integers(*self.lines_per_form) * 7  # 7 is handpicked\n",
    "        px_between_lines = self.rng.integers(*self.px_between_lines)\n",
    "\n",
    "        # Sample line images.\n",
    "        line_width = self.rng.integers(*self.line_width)\n",
    "        lines, target = self.sample_lines(words_to_sample, line_width)\n",
    "\n",
    "        # Concatenate the lines vertically.\n",
    "        form_w = max(l.shape[1] for l in lines)\n",
    "        form_h = sum(l.shape[0] + px_between_lines for l in lines)\n",
    "        if form_h > self.max_height:\n",
    "            print(\n",
    "                \"Generated form height exceeds maximum height. Generating a new form.\"\n",
    "            )\n",
    "            return self.generate_form()\n",
    "        form = np.ones((form_h, form_w), dtype=lines[0].dtype) * 255\n",
    "        curr_h = 0\n",
    "        for line_img in lines:\n",
    "            h, w = line_img.shape\n",
    "            form[curr_h : curr_h + h, :w] = line_img\n",
    "            curr_h += h + px_between_lines\n",
    "\n",
    "        # Add a random amount of padding around the image.\n",
    "        pad_px = self.rng.integers(*self.px_around_image)\n",
    "        new_h, new_w = form.shape[0] + pad_px * 2, form.shape[1] + pad_px * 2\n",
    "        form = A.PadIfNeeded(\n",
    "            new_h, new_w, border_mode=cv.BORDER_CONSTANT, value=255, always_apply=True\n",
    "        )(image=form)[\"image\"]\n",
    "\n",
    "        return form, target\n",
    "\n",
    "    def set_rng(self, seed: int):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def sample_word_image(self) -> Tuple[np.ndarray, str]:\n",
    "        idx = random.randint(0, len(self.iam_words) - 1)\n",
    "        img, target = self.iam_words[idx]\n",
    "        target = \"\".join(self.iam_words.label_enc.inverse_transform(target))\n",
    "        return img, target\n",
    "\n",
    "    def sample_word_image_sequence(\n",
    "        self, words_to_sample: int\n",
    "    ) -> List[Tuple[np.ndarray, str]]:\n",
    "        \"\"\"Sample a sequence of contiguous words.\"\"\"\n",
    "        assert words_to_sample >= 1\n",
    "        start_idx = random.randint(0, len(self.iam_words) - 1)\n",
    "\n",
    "        img_idxs = [start_idx]\n",
    "        img_path = Path(self.iam_words.data.iloc[start_idx][\"img_path\"])\n",
    "        _, _, line_id, word_id = img_path.stem.split(\"-\")\n",
    "        sampled_words = 1\n",
    "        while sampled_words < words_to_sample:\n",
    "            word_id = f\"{int(word_id) + 1 :02}\"\n",
    "            img_name = (\n",
    "                \"-\".join(img_path.stem.split(\"-\")[:-2] + [line_id, word_id]) + \".png\"\n",
    "            )\n",
    "            if not (img_path.parent / img_name).is_file():\n",
    "                # Previous image was the last on its line. Go to the next line.\n",
    "                line_id = f\"{int(line_id) + 1 :02}\"\n",
    "                word_id = \"00\"\n",
    "                img_name = (\n",
    "                    \"-\".join(img_path.stem.split(\"-\")[:-2] + [line_id, word_id])\n",
    "                    + \".png\"\n",
    "                )\n",
    "            if not (img_path.parent / img_name).is_file():\n",
    "                # End of the document.\n",
    "                return self.sample_word_image_sequence(words_to_sample)\n",
    "            # Find the dataset index for the sampled word.\n",
    "            ix = self.iam_words.id_to_idx.get(Path(img_name).stem)\n",
    "            if ix is None:\n",
    "                # If the image has segmentation=err attribute, it will\n",
    "                # not be in the dataset. In this case try again.\n",
    "                return self.sample_word_image_sequence(words_to_sample)\n",
    "            img_idxs.append(ix)\n",
    "            sampled_words += 1\n",
    "\n",
    "        imgs, targets = zip(*[self.iam_words[idx] for idx in img_idxs])\n",
    "        targets = [\n",
    "            \"\".join(self.iam_words.label_enc.inverse_transform(t)) for t in targets\n",
    "        ]\n",
    "        return list(zip(imgs, targets))\n",
    "\n",
    "    def sample_lines(\n",
    "        self, words_to_sample: int, max_line_width: int, sample_one_line: bool = False\n",
    "    ) -> Tuple[Union[List[np.ndarray], np.ndarray], str]:\n",
    "        \"\"\"\n",
    "        Calls `sample_word_image_sequence` several times, using some heuristics\n",
    "        to glue the sequences together.\n",
    "\n",
    "        Returns:\n",
    "            - list of line images\n",
    "            - transcription for all lines combined\n",
    "        \"\"\"\n",
    "        curr_pos, sampled_words = 0, 0\n",
    "        imgs, targets, lines = [], [], []\n",
    "        target_str, last_target = \"\", \"\"\n",
    "\n",
    "        # Sample images.\n",
    "        while sampled_words < words_to_sample:\n",
    "            words_per_seq = self.rng.integers(*self.words_per_sequence)\n",
    "            # Sample a sequence of contiguous words.\n",
    "            img_tgt_seq = self.sample_word_image_sequence(words_per_seq)\n",
    "            for i, (img, tgt) in enumerate(img_tgt_seq):\n",
    "                # Add the sequence to the sampled words so far.\n",
    "                if sampled_words >= words_to_sample:\n",
    "                    break\n",
    "                h, w = img.shape\n",
    "\n",
    "                if curr_pos + w > max_line_width:\n",
    "                    # Concatenate the sampled images into a line.\n",
    "                    line = self.concatenate_line(imgs, targets, max_line_width)\n",
    "\n",
    "                    if sample_one_line:\n",
    "                        return line, target_str\n",
    "\n",
    "                    lines.append(line)\n",
    "                    target_str += \"\\n\"\n",
    "                    last_target = \"\\n\"\n",
    "                    curr_pos = 0\n",
    "                    imgs, targets = [], []\n",
    "\n",
    "                # Basic heuristics to avoid some strange looking sentences.\n",
    "                if i == 0 and (\n",
    "                    (last_target in self.PUNCTUATION and tgt in self.PUNCTUATION)\n",
    "                    or (tgt in self.PUNCTUATION and sampled_words == 0)\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                if (\n",
    "                    sampled_words == 0\n",
    "                    or tgt in [c for c in self.PUNCTUATION if c not in [\"'\", '\"']]\n",
    "                    or last_target == \"\\n\"\n",
    "                ):\n",
    "                    target_str += tgt\n",
    "                else:\n",
    "                    target_str += \" \" + tgt\n",
    "\n",
    "                targets.append(tgt)\n",
    "                imgs.append(img)\n",
    "\n",
    "                sampled_words += 1\n",
    "                last_target = tgt\n",
    "                if tgt in self.PUNCTUATION:\n",
    "                    # Reduce horizontal spacing for punctuation tokens.\n",
    "                    curr_pos = max(0, curr_pos - self.px_between_words)\n",
    "                curr_pos += w + self.px_between_words\n",
    "        if imgs and targets:\n",
    "            # Concatenate the remaining images into a new line.\n",
    "            line = self.concatenate_line(imgs, targets, max_line_width)\n",
    "            lines.append(line)\n",
    "            if sample_one_line:\n",
    "                return line, target_str\n",
    "        return lines, target_str\n",
    "\n",
    "    def concatenate_line(\n",
    "        self, imgs: List[np.ndarray], targets: List[str], line_width: int\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Concatenate a series of (img, target) tuples into a line to create a line image.\n",
    "        \"\"\"\n",
    "        assert len(imgs) == len(targets)\n",
    "\n",
    "        line_height = max(im.shape[0] for im in imgs)\n",
    "        line = np.ones((line_height, line_width), dtype=imgs[0].dtype) * 255\n",
    "\n",
    "        curr_pos = 0\n",
    "        prev_lower_bound = line_height\n",
    "        for img, tgt in zip(imgs, targets):\n",
    "            h, w = img.shape\n",
    "            # Center the image in the middle of the line.\n",
    "            start_h = min(max(0, int((line_height - h) / 2)), line_height - h)\n",
    "\n",
    "            if tgt in [\",\", \".\"]:\n",
    "                # If sampled a comma or dot, place them at the bottom of the line.\n",
    "                start_h = min(max(0, prev_lower_bound - int(h / 2)), line_height - h)\n",
    "            elif tgt in ['\"', \"'\"]:\n",
    "                # If sampled a quote, place them at the top of the line.\n",
    "                start_h = 0\n",
    "            if tgt in self.PUNCTUATION:\n",
    "                # Reduce horizontal spacing for punctuation tokens.\n",
    "                curr_pos = max(0, curr_pos - self.px_between_words)\n",
    "\n",
    "            assert curr_pos + w <= line_width, f\"{curr_pos + w} > {line_width}\"\n",
    "            assert start_h + h <= line_height, f\"{start_h + h} > {line_height}\"\n",
    "\n",
    "            # Concatenate the word image to the line.\n",
    "            line[start_h : start_h + h, curr_pos : curr_pos + w] = img\n",
    "\n",
    "            curr_pos += w + self.px_between_words\n",
    "            prev_lower_bound = start_h + h\n",
    "        return line\n",
    "\n",
    "    @staticmethod\n",
    "    def get_worker_init_fn():\n",
    "        def worker_init_fn(worker_id: int):\n",
    "            set_seed(worker_id)\n",
    "            worker_info = torch.utils.data.get_worker_info()\n",
    "            dataset = worker_info.dataset  # the dataset copy in this worker process\n",
    "            if hasattr(dataset, \"set_rng\"):\n",
    "                dataset.set_rng(worker_id)\n",
    "            else:  # dataset is instance of `IAMDatasetSynthetic` class\n",
    "                dataset.synth_dataset.set_rng(worker_id)\n",
    "\n",
    "        return worker_init_fn\n",
    "\n",
    "\n",
    "class IAMDatasetSynthetic(Dataset):\n",
    "    \"\"\"\n",
    "    A Pytorch dataset combining the IAM dataset with the IAMSyntheticDataGenerator\n",
    "    dataset.\n",
    "\n",
    "    The distribution of real/synthetic images can be controlled by setting the\n",
    "    `synth_prob` argument.\n",
    "    \"\"\"\n",
    "\n",
    "    iam_dataset: IAMDataset\n",
    "    synth_dataset: IAMSyntheticDataGenerator\n",
    "    synth_prob: float\n",
    "\n",
    "    def __init__(self, iam_dataset: IAMDataset, synth_prob: float = 0.3, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            iam_dataset (Dataset): the IAM dataset to sample from\n",
    "            synth_prob (float): the probability of sampling a synthetic image when\n",
    "                calling `__getitem__()`.\n",
    "        \"\"\"\n",
    "        self.iam_dataset = iam_dataset\n",
    "        self.synth_prob = synth_prob\n",
    "        self.synth_dataset = IAMSyntheticDataGenerator(\n",
    "            iam_root=iam_dataset.root,\n",
    "            label_encoder=iam_dataset.label_enc,\n",
    "            transforms=iam_dataset.transforms,\n",
    "            sample_form=(True if iam_dataset.parse_method == \"form\" else False),\n",
    "            only_lowercase=iam_dataset.only_lowercase,\n",
    "            max_height=(\n",
    "                (iam_dataset.data[\"bb_y_end\"] - iam_dataset.data[\"bb_y_start\"]).max()\n",
    "                if iam_dataset.parse_method == \"form\"\n",
    "                else None\n",
    "            ),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        iam = self.iam_dataset\n",
    "        if random.random() > 1 - self.synth_prob:\n",
    "            # Sample from the synthetic dataset.\n",
    "            img, target = self.synth_dataset[0]\n",
    "        else:\n",
    "            # Index the IAM dataset.\n",
    "            img, target = iam[idx]\n",
    "        assert not np.any(np.isnan(img)), img\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.iam_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6750af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e0950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
